{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "y6thty19eS34",
        "outputId": "727fc442-b5e2-495b-c9f5-c8f66cb12658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tổng số ảnh train: 12627\n",
            "Found 12627 validated image filenames belonging to 104 classes.\n",
            "Found 3674 images belonging to 104 classes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,352</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m7,037,504\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)                 │          \u001b[38;5;34m53,352\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,675,496</span> (33.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,675,496\u001b[0m (33.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,995,816</span> (19.06 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,995,816\u001b[0m (19.06 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,679,680</span> (14.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,679,680\u001b[0m (14.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số mẫu train: 12627\n",
            "Steps per epoch: 197\n",
            "Số mẫu validation: 3674\n",
            "Validation steps: 57\n",
            "Epoch 1/30\n",
            "\u001b[1m  1/197\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10:14\u001b[0m 77s/step - accuracy: 0.0156 - loss: 43.9070"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "\n",
        "# Thiết lập tham số\n",
        "im_height, im_width, batch_size, epochs = 224, 224, 64, 30\n",
        "data_path = 'jpeg-224x224/'\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "# Data augmentation cho train - Thêm brightness_range\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.5, 1.5],  # Thêm điều chỉnh độ sáng (0.5 = tối hơn, 1.5 = sáng hơn)\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Chỉ rescale cho validation\n",
        "val_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Thu thập dữ liệu train\n",
        "train_base_path = 'jpeg-224x224/train/'\n",
        "all_train_images = []\n",
        "image_extensions = ['.jpg', '.png', '.jpeg']\n",
        "for dp, dn, filenames in os.walk(train_base_path):\n",
        "    label = os.path.basename(dp)\n",
        "    all_train_images.extend([(os.path.join(dp, f), label) for f in filenames\n",
        "                            if os.path.splitext(f)[1].lower() in image_extensions])\n",
        "\n",
        "if not all_train_images:\n",
        "    print(\"Không tìm thấy ảnh nào trong thư mục train!\")\n",
        "    exit()\n",
        "print(f\"Tổng số ảnh train: {len(all_train_images)}\")\n",
        "\n",
        "train_df = pd.DataFrame({'filename': [img[0] for img in all_train_images],\n",
        "                        'class': [img[1] for img in all_train_images]})\n",
        "\n",
        "# Tạo generator cho train\n",
        "train_data_gen = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    target_size=(im_height, im_width),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Tạo generator cho validation\n",
        "val_dir = os.path.join(data_path, \"val/\")\n",
        "if not os.path.exists(val_dir):\n",
        "    print(\"Thư mục val/ không tồn tại! Vui lòng tạo thư mục và thêm dữ liệu.\")\n",
        "    exit()\n",
        "\n",
        "val_data_gen = val_image_generator.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    target_size=(im_height, im_width),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Tạo mô hình DenseNet121\n",
        "covn_base = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False,\n",
        "                                            input_shape=(224, 224, 3))\n",
        "covn_base.trainable = True\n",
        "for layer in covn_base.layers[:-150]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    covn_base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.02)),  # Thêm lớp Dense mới\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(train_data_gen.class_indices), activation='softmax',\n",
        "                kernel_regularizer=l2(0.02))\n",
        "])\n",
        "\n",
        "# In tóm tắt mô hình\n",
        "model.summary()\n",
        "\n",
        "# Compile mô hình\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=0.0005, weight_decay=0.01, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1),\n",
        "    ModelCheckpoint(filepath='best_model.keras', monitor='val_loss',\n",
        "                   save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Tính steps\n",
        "steps_per_epoch = train_data_gen.n // batch_size\n",
        "validation_steps = val_data_gen.n // batch_size\n",
        "\n",
        "print(f\"Số mẫu train: {train_data_gen.n}\")\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Số mẫu validation: {val_data_gen.n}\")\n",
        "print(f\"Validation steps: {validation_steps}\")\n",
        "\n",
        "# Huấn luyện với dataset lặp lại\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_data_gen,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, im_height, im_width, 3], [None, len(train_data_gen.class_indices)])\n",
        ").repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_data_gen,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, im_height, im_width, 3], [None, len(val_data_gen.class_indices)])\n",
        ").repeat()\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Vẽ biểu đồ train và validation\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"loss\"], label='Train Loss')\n",
        "plt.plot(history.history[\"val_loss\"], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"accuracy\"], label='Train Accuracy')\n",
        "plt.plot(history.history[\"val_accuracy\"], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('train_val_metrics.png')\n",
        "plt.close()\n",
        "\n",
        "# Dự đoán trên ảnh test\n",
        "test_images = [\n",
        "    \"/content//jpeg-224x224/test/003882deb.jpeg\",\n",
        "    \"/content/data1/jpeg-192x192/test/0021f0d33.jpeg\",\n",
        "    \"/content//jpeg-224x224/test/004b88e09.jpeg\",\n",
        "    \"/content/drive/MyDrive/Hình/nho.jpg\",\n",
        "    \"/content/drive/MyDrive/Hình/hd.jpg\",\n",
        "    \"/content/drive/MyDrive/Hình/lili.jpg\"\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "class_indices = train_data_gen.class_indices\n",
        "inverse_dict = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "for ax, img_path in zip(axes, test_images):\n",
        "    if os.path.exists(img_path):\n",
        "        img = Image.open(img_path).resize((224, 224))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_batch = np.expand_dims(img_array, 0)\n",
        "        result = model.predict(img_batch)\n",
        "        predict_class = np.argmax(result)\n",
        "        predicted_label = inverse_dict[predict_class]\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"{predicted_label}\\nConf: {result[0][predict_class]:.2f}\")\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, \"Image not found\", ha='center', va='center')\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_predictions.png')\n",
        "plt.close()\n",
        "\n",
        "# Kiểm tra độ chính xác trên tập test\n",
        "test_dir = os.path.join(data_path, \"test1/\")\n",
        "if not os.path.exists(test_dir):\n",
        "    print(\"Thư mục test/ không tồn tại! Vui lòng tạo thư mục và thêm dữ liệu.\")\n",
        "else:\n",
        "    test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "    test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        target_size=(im_height, im_width),\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_steps = test_data_gen.n // batch_size\n",
        "    test_dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: test_data_gen,\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=([None, im_height, im_width, 3], [None, len(test_data_gen.class_indices)])\n",
        "    ).repeat()\n",
        "\n",
        "    print(f\"Số mẫu test: {test_data_gen.n}\")\n",
        "    print(f\"Test steps: {test_steps}\")\n",
        "    test_loss, test_accuracy = model.evaluate(test_dataset, steps=test_steps)\n",
        "    print(f\"Độ chính xác trên tập test: {test_accuracy * 100:.2f}%\")\n",
        "    print(f\"Loss trên tập test: {test_loss:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot([test_loss], label='Test Loss', marker='o')\n",
        "    plt.legend()\n",
        "    plt.title('Test Loss')\n",
        "    plt.xlabel('Evaluation')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot([test_accuracy], label='Test Accuracy', marker='o')\n",
        "    plt.legend()\n",
        "    plt.title('Test Accuracy')\n",
        "    plt.xlabel('Evaluation')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.savefig('test_metrics.png')\n",
        "    plt.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
